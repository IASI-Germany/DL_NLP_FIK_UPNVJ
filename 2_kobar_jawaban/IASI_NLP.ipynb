{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "punL79CN7Ox6"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_ckMIh7O7s6D"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph5eir3Pf-3z"
   },
   "source": [
    "# Optimizing the Text Generation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5Uhzt6vVIB2"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DTSense/Webinar_DeepLearning_4/blob/master/1_kobar_latihan/DTSense_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aHK2CYygXom"
   },
   "source": [
    "## Import TensorFlow and related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LmLTREBf5ng"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Other imports for processing data\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmLTO_dpgge9"
   },
   "source": [
    "## Get the Dataset\n",
    "\n",
    "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Bf5FVHfganK",
    "outputId": "56830fff-c312-46e8-bd0d-d6c05cf9e7e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-12 19:02:17--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
      "Resolving drive.google.com (drive.google.com)... 74.125.135.100, 74.125.135.139, 74.125.135.101, ...\n",
      "Connecting to drive.google.com (drive.google.com)|74.125.135.100|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mf1jme16nrodqg2dir5i94hhpkc1vht4/1607799675000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2020-12-12 19:02:19--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mf1jme16nrodqg2dir5i94hhpkc1vht4/1607799675000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
      "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.28.132, 2607:f8b0:400e:c04::84\n",
      "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.28.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘/tmp/songdata.csv’\n",
      "\n",
      "/tmp/songdata.csv       [  <=>               ]  69.08M   284MB/s    in 0.2s    \n",
      "\n",
      "2020-12-12 19:02:20 (284 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
    "    -O /tmp/songdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "VNbB4vMRT4N7",
    "outputId": "f8c06c27-6fd6-4f04-8057-298c8bc59734"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Burning My Bridges</td>\n",
       "      <td>/a/abba/burning+my+bridges_20003011.html</td>\n",
       "      <td>Well, you hoot and you holler and you make me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Cassandra</td>\n",
       "      <td>/a/abba/cassandra_20002811.html</td>\n",
       "      <td>Down in the street they're all singing and sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Chiquitita</td>\n",
       "      <td>/a/abba/chiquitita_20002978.html</td>\n",
       "      <td>Chiquitita, tell me what's wrong  \\nYou're enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Crazy World</td>\n",
       "      <td>/a/abba/crazy+world_20003013.html</td>\n",
       "      <td>I was out with the morning sun  \\nCouldn't sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Crying Over You</td>\n",
       "      <td>/a/abba/crying+over+you_20177611.html</td>\n",
       "      <td>I'm waitin' for you baby  \\nI'm sitting all al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist  ...                                               text\n",
       "0   ABBA  ...  Look at her face, it's a wonderful face  \\nAnd...\n",
       "1   ABBA  ...  Take it easy with me, please  \\nTouch me gentl...\n",
       "2   ABBA  ...  I'll never know why I had to go  \\nWhy I had t...\n",
       "3   ABBA  ...  Making somebody happy is a question of give an...\n",
       "4   ABBA  ...  Making somebody happy is a question of give an...\n",
       "5   ABBA  ...  Well, you hoot and you holler and you make me ...\n",
       "6   ABBA  ...  Down in the street they're all singing and sho...\n",
       "7   ABBA  ...  Chiquitita, tell me what's wrong  \\nYou're enc...\n",
       "8   ABBA  ...  I was out with the morning sun  \\nCouldn't sle...\n",
       "9   ABBA  ...  I'm waitin' for you baby  \\nI'm sitting all al...\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from csv - this time with 250 songs\n",
    "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWbMN_19jfRT"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRmPPJegovBe"
   },
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer\n",
    "\n",
    "def create_lyrics_corpus(dataset, field):\n",
    "  # Remove all other punctuation\n",
    "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
    "  # Make it lowercase\n",
    "  dataset[field] = dataset[field].str.lower()\n",
    "  # Make it one long string to split by line\n",
    "  lyrics = dataset[field].str.cat()\n",
    "  corpus = lyrics.split('\\n')\n",
    "  # Remove any trailing whitespace\n",
    "  for l in range(len(corpus)):\n",
    "    corpus[l] = corpus[l].rstrip()\n",
    "  # Remove any empty lines\n",
    "  corpus = [l for l in corpus if l != '']\n",
    "\n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jKcVrbRrnH-n",
    "outputId": "86f6252e-3c02-4ea4-d606-9e80e1f04474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# Create the corpus using the 'text' column containing lyrics\n",
    "corpus = create_lyrics_corpus(dataset, 'text')\n",
    "# Tokenize the corpus\n",
    "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
    "total_words = tokenizer.num_words\n",
    "\n",
    "# There should be a lot more words now\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iycX-gUTZFnn"
   },
   "source": [
    "### Create Sequences and Labels\n",
    "\n",
    "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkLAf3HmkPSo"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tsequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences for equal input length \n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
    "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "# One-hot encode the labels\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_m5LB-6YVWe"
   },
   "outputs": [],
   "source": [
    "# Check out how some of our data is being stored\n",
    "# The Tokenizer has just a single index per word\n",
    "print(tokenizer.word_index['know'])\n",
    "print(tokenizer.word_index['feeling'])\n",
    "# Input sequences will have multiple indexes\n",
    "print(input_sequences[5])\n",
    "print(input_sequences[6])\n",
    "# And the one hot labels will be as long as the full spread of tokenized words\n",
    "print(one_hot_labels[5])\n",
    "print(one_hot_labels[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KCRvoEaYunE"
   },
   "source": [
    "### Train a Text Generation Model\n",
    "\n",
    "Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n",
    "\n",
    "From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nHOp6uWlP_P",
    "outputId": "fd3214f2-f500-4bb9-9939-3f7a2ffd4259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 7.1253 - accuracy: 0.0202\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.5985 - accuracy: 0.0399\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.4464 - accuracy: 0.0338\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.4010 - accuracy: 0.0399\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.3515 - accuracy: 0.0333\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.2881 - accuracy: 0.0383\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.2309 - accuracy: 0.0388\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1802 - accuracy: 0.0404\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1377 - accuracy: 0.0394\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1048 - accuracy: 0.0459\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.0752 - accuracy: 0.0505\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.0480 - accuracy: 0.0510\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.0253 - accuracy: 0.0484\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.0040 - accuracy: 0.0510\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.9855 - accuracy: 0.0469\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.9670 - accuracy: 0.0510\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.9484 - accuracy: 0.0520\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.9304 - accuracy: 0.0454\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.9097 - accuracy: 0.0484\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.8930 - accuracy: 0.0489\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.8726 - accuracy: 0.0489\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.8520 - accuracy: 0.0469\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.8265 - accuracy: 0.0510\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.8012 - accuracy: 0.0505\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.7770 - accuracy: 0.0580\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.7499 - accuracy: 0.0545\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.7250 - accuracy: 0.0530\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.6969 - accuracy: 0.0580\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.6676 - accuracy: 0.0565\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.6381 - accuracy: 0.0676\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.6023 - accuracy: 0.0747\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.5669 - accuracy: 0.0742\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.5328 - accuracy: 0.0994\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.4964 - accuracy: 0.1049\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.4629 - accuracy: 0.1070\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.4272 - accuracy: 0.1160\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.3931 - accuracy: 0.1191\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.3581 - accuracy: 0.1241\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.3256 - accuracy: 0.1317\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.2917 - accuracy: 0.1372\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 4.2593 - accuracy: 0.1443\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.2252 - accuracy: 0.1504\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.1932 - accuracy: 0.1509\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.1578 - accuracy: 0.1554\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.1270 - accuracy: 0.1650\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.0936 - accuracy: 0.1635\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.0619 - accuracy: 0.1816\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.0290 - accuracy: 0.1781\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.9988 - accuracy: 0.2023\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.9671 - accuracy: 0.2008\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.9348 - accuracy: 0.2124\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.9041 - accuracy: 0.2215\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.8727 - accuracy: 0.2215\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.8391 - accuracy: 0.2321\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.8099 - accuracy: 0.2326\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.7785 - accuracy: 0.2397\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.7456 - accuracy: 0.2452\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.7162 - accuracy: 0.2477\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.6837 - accuracy: 0.2518\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.6526 - accuracy: 0.2629\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.6212 - accuracy: 0.2624\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.5905 - accuracy: 0.2709\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.5597 - accuracy: 0.2800\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.5262 - accuracy: 0.2810\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4963 - accuracy: 0.2886\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.4643 - accuracy: 0.2967\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.4341 - accuracy: 0.2997\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.4023 - accuracy: 0.3118\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.3714 - accuracy: 0.3244\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.3389 - accuracy: 0.3204\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.3090 - accuracy: 0.3300\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.2784 - accuracy: 0.3320\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.2454 - accuracy: 0.3396\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.2179 - accuracy: 0.3461\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.1864 - accuracy: 0.3557\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.1566 - accuracy: 0.3572\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.1277 - accuracy: 0.3688\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.0942 - accuracy: 0.3633\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.0664 - accuracy: 0.3658\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.0374 - accuracy: 0.3744\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.0089 - accuracy: 0.3840\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.9797 - accuracy: 0.3829\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.9501 - accuracy: 0.3890\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.9246 - accuracy: 0.3905\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.8933 - accuracy: 0.3991\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.8638 - accuracy: 0.4067\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.8401 - accuracy: 0.4127\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.8132 - accuracy: 0.4132\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.7856 - accuracy: 0.4223\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.7619 - accuracy: 0.4263\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.7361 - accuracy: 0.4289\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.7109 - accuracy: 0.4304\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.6859 - accuracy: 0.4384\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.6597 - accuracy: 0.4400\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.6335 - accuracy: 0.4435\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.6084 - accuracy: 0.4485\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.5816 - accuracy: 0.4506\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.5575 - accuracy: 0.4576\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.5325 - accuracy: 0.4612\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.5091 - accuracy: 0.4642\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgvIz20nlQcq"
   },
   "source": [
    "### View the Training Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "rOqmmarvlSLh",
    "outputId": "be8d74a1-01b2-4a10-d8a0-4988f4f7ae4e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnkDwVT_Y0_y"
   },
   "source": [
    "### Generate new lyrics!\n",
    "\n",
    "It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEfcTrQvVNz5",
    "outputId": "2013b922-42e3-4a33-e6d3-89be9d9241f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills me sing and i am your boomaboomerang and on my eyes never leave me feel fine end leave me feel fine end quiet quiet quiet end but like i eyes believe i eyes believe you leave me girl girl without you feel so on give and take of us know quiet quiet quiet quiet quiet quiet quiet quiet quiet world quiet quiet quiet quiet world eyes andante blue eyes dont am believe return to sender girl girl without good as new what a crazy world so quiet end but tender every eyes believe andante andante andante andante andante andante andante\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz9x-7dWihxx"
   },
   "source": [
    "## 250 Songs\n",
    "\n",
    "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
    "\n",
    "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "qcN8cIPQUvUU",
    "outputId": "bedd3819-a246-46f8-fd96-f770775e7f0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Air Supply</td>\n",
       "      <td>Believer</td>\n",
       "      <td>/a/air+supply/believer_20522284.html</td>\n",
       "      <td>Believer  \\nI got no where to go  \\nBeliever  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Air Supply</td>\n",
       "      <td>Big Cat</td>\n",
       "      <td>/a/air+supply/big+cat_20522283.html</td>\n",
       "      <td>Big cat walking on the wild side  \\nBig cat ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Air Supply</td>\n",
       "      <td>Black And Blue</td>\n",
       "      <td>/a/air+supply/black+and+blue_20154341.html</td>\n",
       "      <td>Blue, blue is the color of skies  \\nBlue is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Air Supply</td>\n",
       "      <td>Body Glove</td>\n",
       "      <td>/a/air+supply/body+glove_20522282.html</td>\n",
       "      <td>The more you win, the more you gain  \\nAn open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Air Supply</td>\n",
       "      <td>Book Of Love</td>\n",
       "      <td>/a/air+supply/book+of+love_20522281.html</td>\n",
       "      <td>The book of love, that sacred place  \\nWhere w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist  ...                                               text\n",
       "0          ABBA  ...  Look at her face, it's a wonderful face  \\nAnd...\n",
       "1          ABBA  ...  Take it easy with me, please  \\nTouch me gentl...\n",
       "2          ABBA  ...  I'll never know why I had to go  \\nWhy I had t...\n",
       "3          ABBA  ...  Making somebody happy is a question of give an...\n",
       "4          ABBA  ...  Making somebody happy is a question of give an...\n",
       "..          ...  ...                                                ...\n",
       "245  Air Supply  ...  Believer  \\nI got no where to go  \\nBeliever  ...\n",
       "246  Air Supply  ...  Big cat walking on the wild side  \\nBig cat ta...\n",
       "247  Air Supply  ...  Blue, blue is the color of skies  \\nBlue is th...\n",
       "248  Air Supply  ...  The more you win, the more you gain  \\nAn open...\n",
       "249  Air Supply  ...  The book of love, that sacred place  \\nWhere w...\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from csv - this time with 250 songs\n",
    "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdEhZfp9U5R9",
    "outputId": "291155ff-8ed8-47f6-80d0-ebc56c29187c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# Create the corpus using the 'text' column containing lyrics\n",
    "corpus = create_lyrics_corpus(dataset, 'text')\n",
    "# Tokenize the corpus\n",
    "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
    "total_words = tokenizer.num_words\n",
    "\n",
    "# There should be a lot more words now\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVxqTCkDU_ee"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tsequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences for equal input length \n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
    "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "# One-hot encode the labels\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cECbqT-blMk-"
   },
   "source": [
    "### Train a (Better) Text Generation Model\n",
    "\n",
    "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUqEuVvfVEI5",
    "outputId": "5e8ddd72-053f-488d-98f1-a2869705137d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 5.9800 - accuracy: 0.0463\n",
      "Epoch 2/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 5.6578 - accuracy: 0.0520\n",
      "Epoch 3/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 5.4555 - accuracy: 0.0709\n",
      "Epoch 4/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 5.2779 - accuracy: 0.1001\n",
      "Epoch 5/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 5.1254 - accuracy: 0.1204\n",
      "Epoch 6/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 5.0091 - accuracy: 0.1283\n",
      "Epoch 7/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.8999 - accuracy: 0.1394\n",
      "Epoch 8/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.7826 - accuracy: 0.1502\n",
      "Epoch 9/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.6549 - accuracy: 0.1625\n",
      "Epoch 10/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.5311 - accuracy: 0.1747\n",
      "Epoch 11/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.4118 - accuracy: 0.1889\n",
      "Epoch 12/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.3029 - accuracy: 0.2027\n",
      "Epoch 13/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.2114 - accuracy: 0.2157\n",
      "Epoch 14/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.1232 - accuracy: 0.2242\n",
      "Epoch 15/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 4.0426 - accuracy: 0.2323\n",
      "Epoch 16/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.9660 - accuracy: 0.2433\n",
      "Epoch 17/100\n",
      "1480/1480 [==============================] - 13s 8ms/step - loss: 3.8950 - accuracy: 0.2527\n",
      "Epoch 18/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.8299 - accuracy: 0.2637\n",
      "Epoch 19/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.7712 - accuracy: 0.2718\n",
      "Epoch 20/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.7169 - accuracy: 0.2772\n",
      "Epoch 21/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6631 - accuracy: 0.2858\n",
      "Epoch 22/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6130 - accuracy: 0.2936\n",
      "Epoch 23/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5674 - accuracy: 0.2984\n",
      "Epoch 24/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5199 - accuracy: 0.3059\n",
      "Epoch 25/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.4774 - accuracy: 0.3109\n",
      "Epoch 26/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 3.4377 - accuracy: 0.3156\n",
      "Epoch 27/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3995 - accuracy: 0.3226\n",
      "Epoch 28/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3641 - accuracy: 0.3288\n",
      "Epoch 29/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3295 - accuracy: 0.3338\n",
      "Epoch 30/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2978 - accuracy: 0.3372\n",
      "Epoch 31/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 3.2636 - accuracy: 0.3420\n",
      "Epoch 32/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2350 - accuracy: 0.3466\n",
      "Epoch 33/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2037 - accuracy: 0.3526\n",
      "Epoch 34/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1744 - accuracy: 0.3568\n",
      "Epoch 35/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1460 - accuracy: 0.3616\n",
      "Epoch 36/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1213 - accuracy: 0.3667\n",
      "Epoch 37/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0947 - accuracy: 0.3699\n",
      "Epoch 38/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0722 - accuracy: 0.3751\n",
      "Epoch 39/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0475 - accuracy: 0.3783\n",
      "Epoch 40/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0257 - accuracy: 0.3821\n",
      "Epoch 41/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0049 - accuracy: 0.3849\n",
      "Epoch 42/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9822 - accuracy: 0.3888\n",
      "Epoch 43/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9606 - accuracy: 0.3928\n",
      "Epoch 44/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9397 - accuracy: 0.3947\n",
      "Epoch 45/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9180 - accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9079 - accuracy: 0.3997\n",
      "Epoch 47/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8819 - accuracy: 0.4055\n",
      "Epoch 48/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.8658 - accuracy: 0.4096\n",
      "Epoch 49/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8476 - accuracy: 0.4115\n",
      "Epoch 50/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8301 - accuracy: 0.4137\n",
      "Epoch 51/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8190 - accuracy: 0.4147\n",
      "Epoch 52/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7997 - accuracy: 0.4192\n",
      "Epoch 53/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7838 - accuracy: 0.4219\n",
      "Epoch 54/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7649 - accuracy: 0.4251\n",
      "Epoch 55/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7560 - accuracy: 0.4249\n",
      "Epoch 56/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7358 - accuracy: 0.4298\n",
      "Epoch 57/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7212 - accuracy: 0.4329\n",
      "Epoch 58/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7123 - accuracy: 0.4352\n",
      "Epoch 59/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6923 - accuracy: 0.4368\n",
      "Epoch 60/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6835 - accuracy: 0.4382\n",
      "Epoch 61/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6645 - accuracy: 0.4410\n",
      "Epoch 62/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6554 - accuracy: 0.4454\n",
      "Epoch 63/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6425 - accuracy: 0.4468\n",
      "Epoch 64/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6301 - accuracy: 0.4485\n",
      "Epoch 65/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6127 - accuracy: 0.4499\n",
      "Epoch 66/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6092 - accuracy: 0.4525\n",
      "Epoch 67/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5856 - accuracy: 0.4553\n",
      "Epoch 68/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5799 - accuracy: 0.4575\n",
      "Epoch 69/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5687 - accuracy: 0.4597\n",
      "Epoch 70/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5546 - accuracy: 0.4619\n",
      "Epoch 71/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5425 - accuracy: 0.4635\n",
      "Epoch 72/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5343 - accuracy: 0.4654\n",
      "Epoch 73/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5287 - accuracy: 0.4662\n",
      "Epoch 74/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5188 - accuracy: 0.4670\n",
      "Epoch 75/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5122 - accuracy: 0.4693\n",
      "Epoch 76/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4989 - accuracy: 0.4720\n",
      "Epoch 77/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4817 - accuracy: 0.4756\n",
      "Epoch 78/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4728 - accuracy: 0.4756\n",
      "Epoch 79/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4661 - accuracy: 0.4768\n",
      "Epoch 80/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4591 - accuracy: 0.4788\n",
      "Epoch 81/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4462 - accuracy: 0.4797\n",
      "Epoch 82/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4347 - accuracy: 0.4840\n",
      "Epoch 83/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4292 - accuracy: 0.4858\n",
      "Epoch 84/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4197 - accuracy: 0.4848\n",
      "Epoch 85/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4129 - accuracy: 0.4862\n",
      "Epoch 86/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3921 - accuracy: 0.4909\n",
      "Epoch 87/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3870 - accuracy: 0.4918\n",
      "Epoch 88/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3907 - accuracy: 0.4901\n",
      "Epoch 89/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3791 - accuracy: 0.4909\n",
      "Epoch 90/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3644 - accuracy: 0.4963\n",
      "Epoch 91/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3554 - accuracy: 0.4963\n",
      "Epoch 92/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3497 - accuracy: 0.4979\n",
      "Epoch 93/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3497 - accuracy: 0.4986\n",
      "Epoch 94/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3454 - accuracy: 0.4982\n",
      "Epoch 95/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3519 - accuracy: 0.4958\n",
      "Epoch 96/100\n",
      "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3161 - accuracy: 0.5044\n",
      "Epoch 97/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3211 - accuracy: 0.5023\n",
      "Epoch 98/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3051 - accuracy: 0.5057\n",
      "Epoch 99/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3017 - accuracy: 0.5070\n",
      "Epoch 100/100\n",
      "1480/1480 [==============================] - 12s 8ms/step - loss: 2.2945 - accuracy: 0.5078\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "S6bvq6SjVGFA",
    "outputId": "84a3cfe4-4330-4202-82c3-faa0419dbbdf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISLZZGlQlSxh"
   },
   "source": [
    "### Generate better lyrics!\n",
    "\n",
    "This time around, we should be able to get a more interesting output with less repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P96oVMk3lU7y",
    "outputId": "b5d54a00-aa39-4f49-bff0-9c7e5b2cf205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills me to the bone that you think me start you feel the pain i miss lovin you and joe round and seas questions tonight might sounds knew beast believed reaching games first talked temperature cloud beast ball point rights cloud light of female company likes rushing paint knew the devil are your brother reaching dice honey i did you humdehumhum never never never be me for a little good with a minute honolulu this block beyond learn lucky i do is flowing over over bags your female dreamworld likes rushing open grown travel row starts memries x4 noises noises glowing\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upgJKV8_oRU9"
   },
   "source": [
    "### Varying the Possible Outputs\n",
    "\n",
    "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
    "\n",
    "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZe9gaJeoGVP",
    "outputId": "f1e662ab-5d66-4246-94a4-2099309afd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n"
     ]
    }
   ],
   "source": [
    "# Test the method with just the first word after the seed text\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted_probs = model.predict(token_list)[0]\n",
    "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
    "                             p=predicted_probs)\n",
    "# Running this cell multiple times should get you some variance in output\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee7WKgRGrJy1",
    "outputId": "4cb354e3-e1a6-4b95-a983-d7fd48aa25a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills until you humdehumhum showed he gently knew without to stay hawaii track hawaii bitch of the real last female company falling knew im going crazy in dark kin minds softly earth day smokin stinky heh x2 wants rushing knows wed school around my reaching beyond glory beats cow silly eats horns its done street im here is me make my trees sailing miss its breaking this ball man will see going through following following feeling next smiles if with reaching but we humdehumhum the breakfast humdehumhum in not sore eyes the office half her song gotta hoppin lights lights state\n"
     ]
    }
   ],
   "source": [
    "# Use this process for the full output generation\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "  predicted_probs = model.predict(token_list)[0]\n",
    "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
    "                               p=predicted_probs)\n",
    "  output_word = \"\"\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted:\n",
    "      output_word = word\n",
    "      break\n",
    "  seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8Hl9pOkAJjc"
   },
   "source": [
    "## Credits (Reference)\n",
    "\n",
    "> - [Lex Fridman's MIT Deep Learning](https://github.com/lexfridman/mit-deep-learning)\n",
    "> - [Intro to TensorFlow Udacity](https://classroom.udacity.com/courses/ud187/l)\n",
    "> - [TensorFlow Examples Constructing Text Generation](https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb)\n",
    "> - [TensorFlow Examples Optimizing Text Generation](https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb)\n",
    "> - [TensorFlow Tutorial](https://www.tensorflow.org/tutorials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p36MPA7MdrEp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DTSense_NLP",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
